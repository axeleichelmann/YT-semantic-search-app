{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation Notebook\n",
    "In this notebook we carry out experiments to find the best model to use for our semantic search app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/axel/Desktop/machine_learning/ShawTalebi_FSDS/env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/axel/Desktop/machine_learning/ShawTalebi_FSDS/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics import DistanceMetric\n",
    "\n",
    "from utils import evalTrueRankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/video-transcripts.parquet')\n",
    "df_eval = pd.read_csv('data/eval-raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ai consulting</td>\n",
       "      <td>INlCLmWlojY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fine tuning llm</td>\n",
       "      <td>eC6Hd1hFvos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When do you recommend fine tunning and when do...</td>\n",
       "      <td>eC6Hd1hFvos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llm from scratch</td>\n",
       "      <td>ZLbVdvOoTKM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What if you could make a small language model,...</td>\n",
       "      <td>ZLbVdvOoTKM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Fat tails python</td>\n",
       "      <td>15Kd9OPn7tw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>do more with less</td>\n",
       "      <td>poGxnBR3hEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>data science projects</td>\n",
       "      <td>03x2oYg9oME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>how to become a data scientist</td>\n",
       "      <td>W6TkOTsI7vM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Conflict resolution</td>\n",
       "      <td>m19FqRrmvIE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query     video_id\n",
       "0                                       ai consulting  INlCLmWlojY\n",
       "1                                     fine tuning llm  eC6Hd1hFvos\n",
       "2   When do you recommend fine tunning and when do...  eC6Hd1hFvos\n",
       "3                                    llm from scratch  ZLbVdvOoTKM\n",
       "4   What if you could make a small language model,...  ZLbVdvOoTKM\n",
       "..                                                ...          ...\n",
       "59                                   Fat tails python  15Kd9OPn7tw\n",
       "60                                  do more with less  poGxnBR3hEU\n",
       "61                              data science projects  03x2oYg9oME\n",
       "62                     how to become a data scientist  W6TkOTsI7vM\n",
       "63                                Conflict resolution  m19FqRrmvIE\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed Titles and Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 'parameters'\n",
    "column_to_embed_list = ['title', 'transcript']\n",
    "model_name_list = [\"all-MiniLM-L6-v2\", \"multi-qa-distilbert-cos-v1\", \"multi-qa-mpnet-base-dot-v1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2_title\n",
      "CPU times: user 408 ms, sys: 164 ms, total: 572 ms\n",
      "Wall time: 4.84 s\n",
      "\n",
      "all-MiniLM-L6-v2_transcript\n",
      "CPU times: user 1.21 s, sys: 190 ms, total: 1.4 s\n",
      "Wall time: 1.56 s\n",
      "\n",
      "multi-qa-distilbert-cos-v1_title\n",
      "CPU times: user 208 ms, sys: 50.7 ms, total: 258 ms\n",
      "Wall time: 595 ms\n",
      "\n",
      "multi-qa-distilbert-cos-v1_transcript\n",
      "CPU times: user 1.06 s, sys: 376 ms, total: 1.43 s\n",
      "Wall time: 4.33 s\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1_title\n",
      "CPU times: user 276 ms, sys: 151 ms, total: 427 ms\n",
      "Wall time: 2.24 s\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1_transcript\n",
      "CPU times: user 3.16 s, sys: 356 ms, total: 3.52 s\n",
      "Wall time: 8.49 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for each possible combination of columns and model\n",
    "\n",
    "# Initialize dictionary to keep track of all text embeddings\n",
    "text_embedding_dict = {}\n",
    "\n",
    "for model_name in model_name_list:\n",
    "\n",
    "    # Define Embedding Model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    for column_name in column_to_embed_list:\n",
    "        # Define text embedding identifier\n",
    "        key_name = model_name + \"_\" + column_name\n",
    "        print(key_name)\n",
    "\n",
    "        # Generate text embeddings for text under column_name\n",
    "        %time embedding_arr = model.encode(df[column_name].to_list())\n",
    "        print('')\n",
    "\n",
    "        # Append Embeddings to dictionary\n",
    "        text_embedding_dict[key_name] = embedding_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed Queries in the Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2\n",
      "CPU times: user 200 ms, sys: 262 ms, total: 461 ms\n",
      "Wall time: 1.6 s\n",
      "\n",
      "multi-qa-distilbert-cos-v1\n",
      "CPU times: user 148 ms, sys: 244 ms, total: 392 ms\n",
      "Wall time: 599 ms\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1\n",
      "CPU times: user 581 ms, sys: 377 ms, total: 958 ms\n",
      "Wall time: 1.76 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionary to keep track of query embeddings\n",
    "query_embedding_dict = {}\n",
    "\n",
    "for model_name in model_name_list:\n",
    "\n",
    "    # Define Embedding Model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    print(model_name)\n",
    "\n",
    "    %time embedding_arr = model.encode(df_eval['query'].to_list())\n",
    "    print('')\n",
    "\n",
    "    query_embedding_dict[model_name] = embedding_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Semantic Search Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize distance metrics to experiment with\n",
    "dist_name_list = ['euclidean', 'manhattan', 'chebyshev']\n",
    "sim_name_list = ['cos_sim', 'dot_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all possible combinations of model, column to embed, and distance metric\n",
    "\n",
    "# Initialize list in which to store results\n",
    "eval_results = []\n",
    "\n",
    "# Loop through embedding models\n",
    "for model_name in model_name_list:\n",
    "    query_embedding = query_embedding_dict[model_name]   # Get query embeddings\n",
    "\n",
    "    # Loop through text columns\n",
    "    for column_name in column_to_embed_list:\n",
    "        embedding_arr = text_embedding_dict[model_name + \"_\" + column_name]   # Get text embeddings\n",
    "\n",
    "        # Loop through distance metrics\n",
    "        for dist_name in dist_name_list:\n",
    "            # Compute distance between video text and query\n",
    "            dist = DistanceMetric.get_metric(dist_name)\n",
    "            dist_arr = dist.pairwise(embedding_arr, query_embedding)\n",
    "            dist_arr_sorted = np.argsort(dist_arr, axis=0)  # Sort indexes of distance array from smallest -> largest\n",
    "\n",
    "            # Define label for search method\n",
    "            method_name = \"_\".join([model_name, column_name, dist_name])\n",
    "\n",
    "            # Evaluate the ranking of the ground truth label - query distance for this method_name\n",
    "            truth_rank_arr = evalTrueRankings(dist_arr_sorted, df, df_eval)\n",
    "            eval_list = [method_name] + truth_rank_arr.tolist()[0]\n",
    "            eval_results.append(eval_list)\n",
    "\n",
    "        # Loop through sbert similarity scores\n",
    "        for sim_name in sim_name_list:\n",
    "            # Apply similarity score from sbert\n",
    "            cmd = \"dist_arr = -util.\" + sim_name + \"(embedding_arr, query_embedding)\"\n",
    "            exec(cmd)\n",
    "            dist_arr_sorted = np.argsort(dist_arr, axis=0)   # Sort indexes of distance array \n",
    "\n",
    "            # Define label for search method\n",
    "            method_name = \"_\".join([model_name, column_name, sim_name.replace('_','-')])\n",
    "\n",
    "            # Evaluate the ranking of the ground truth label - query distance for this method_name\n",
    "            truth_rank_arr = evalTrueRankings(dist_arr_sorted, df, df_eval)\n",
    "            eval_list = [method_name] + truth_rank_arr.tolist()[0]\n",
    "            eval_results.append(eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute rankings for title + transcript embedding\n",
    "for model_name in model_name_list:\n",
    "\n",
    "    # Generate text & query embeddings\n",
    "    embedding_arr1 = text_embedding_dict[model_name+\"_title\"]\n",
    "    embedding_arr2 = text_embedding_dict[model_name+\"_transcript\"]\n",
    "    query_embedding = query_embedding_dict[model_name]\n",
    "\n",
    "    # Loop through distance metrics\n",
    "    for dist_name in dist_name_list:\n",
    "        # Compute distance between video text and query\n",
    "        dist = DistanceMetric.get_metric(dist_name)\n",
    "        dist_arr = dist.pairwise(embedding_arr1, query_embedding) + dist.pairwise(embedding_arr2, query_embedding)\n",
    "        dist_arr_sorted = np.argsort(dist_arr, axis=0)  # Sort indexes of distance array from smallest -> largest\n",
    "\n",
    "        # Define label for search method\n",
    "        method_name = \"_\".join([model_name, \"title-transcript\", dist_name])\n",
    "\n",
    "        # Evaluate the ranking of the ground truth label - query distance for this method_name\n",
    "        truth_rank_arr = evalTrueRankings(dist_arr_sorted, df, df_eval)\n",
    "        eval_list = [method_name] + truth_rank_arr.tolist()[0]\n",
    "        eval_results.append(eval_list)\n",
    "\n",
    "    # Loop through sbert similarity scores\n",
    "    for sim_name in sim_name_list:\n",
    "        # Apply similarity score from sbert\n",
    "        cmd = \"dist_arr = -util.\" + sim_name + \"(embedding_arr1, query_embedding) - util.\" + sim_name + \"(embedding_arr2, query_embedding)\"\n",
    "        exec(cmd)\n",
    "        dist_arr_sorted = np.argsort(dist_arr, axis=0)   # Sort indexes of distance array \n",
    "\n",
    "        # Define label for search method\n",
    "        method_name = \"_\".join([model_name, column_name, sim_name.replace(\"_\",\"-\")])\n",
    "\n",
    "        # Evaluate the ranking of the ground truth label - query distance for this method_name\n",
    "        truth_rank_arr = evalTrueRankings(dist_arr_sorted, df, df_eval)\n",
    "        eval_list = [method_name] + truth_rank_arr.tolist()[0]\n",
    "        eval_results.append(eval_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results as a pandas dataframe\n",
    "\n",
    "data = {'method_name' : [eval_results[i][0] for i in range(len(eval_results))]}\n",
    "\n",
    "for method_num in range(len(eval_results)):\n",
    "    for query_num in range(len(eval_results[0])-1):\n",
    "        if method_num == 0:\n",
    "            data['rank-query-'+str(query_num)] = []\n",
    "            data['rank-query-'+str(query_num)].append(eval_results[method_num][query_num+1])\n",
    "        else:\n",
    "            data['rank-query-'+str(query_num)].append(eval_results[method_num][query_num+1])\n",
    "\n",
    "df_results = pd.DataFrame(data)\n",
    "print(df_results.shape)\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method_name</th>\n",
       "      <th>rank-query-0</th>\n",
       "      <th>rank-query-1</th>\n",
       "      <th>rank-query-2</th>\n",
       "      <th>rank-query-3</th>\n",
       "      <th>rank-query-4</th>\n",
       "      <th>rank-query-5</th>\n",
       "      <th>rank-query-6</th>\n",
       "      <th>rank-query-7</th>\n",
       "      <th>rank-query-8</th>\n",
       "      <th>...</th>\n",
       "      <th>rank-query-57</th>\n",
       "      <th>rank-query-58</th>\n",
       "      <th>rank-query-59</th>\n",
       "      <th>rank-query-60</th>\n",
       "      <th>rank-query-61</th>\n",
       "      <th>rank-query-62</th>\n",
       "      <th>rank-query-63</th>\n",
       "      <th>rank-query-mean</th>\n",
       "      <th>num_in_top-1</th>\n",
       "      <th>num_in_top-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all-MiniLM-L6-v2_title_euclidean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all-MiniLM-L6-v2_title_manhattan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.265625</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all-MiniLM-L6-v2_title_chebyshev</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.406250</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all-MiniLM-L6-v2_title_cos-sim</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all-MiniLM-L6-v2_title_dot-score</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        method_name  rank-query-0  rank-query-1  rank-query-2  \\\n",
       "0  all-MiniLM-L6-v2_title_euclidean           0.0           1.0          22.0   \n",
       "1  all-MiniLM-L6-v2_title_manhattan           0.0           1.0           9.0   \n",
       "2  all-MiniLM-L6-v2_title_chebyshev           0.0           3.0          51.0   \n",
       "3    all-MiniLM-L6-v2_title_cos-sim           0.0           1.0          22.0   \n",
       "4  all-MiniLM-L6-v2_title_dot-score           0.0           1.0          22.0   \n",
       "\n",
       "   rank-query-3  rank-query-4  rank-query-5  rank-query-6  rank-query-7  \\\n",
       "0           0.0          16.0           0.0           0.0           0.0   \n",
       "1           0.0          14.0           0.0           0.0           0.0   \n",
       "2           0.0          79.0           0.0           0.0           0.0   \n",
       "3           0.0          16.0           0.0           0.0           0.0   \n",
       "4           0.0          16.0           0.0           0.0           0.0   \n",
       "\n",
       "   rank-query-8  ...  rank-query-57  rank-query-58  rank-query-59  \\\n",
       "0           0.0  ...            0.0            0.0            0.0   \n",
       "1           0.0  ...            0.0            0.0            0.0   \n",
       "2           0.0  ...            0.0            0.0            0.0   \n",
       "3           0.0  ...            0.0            0.0            0.0   \n",
       "4           0.0  ...            0.0            0.0            0.0   \n",
       "\n",
       "   rank-query-60  rank-query-61  rank-query-62  rank-query-63  \\\n",
       "0            1.0            0.0            1.0            0.0   \n",
       "1            1.0            0.0            1.0            0.0   \n",
       "2            1.0            0.0            1.0            0.0   \n",
       "3            1.0            0.0            1.0            0.0   \n",
       "4            1.0            0.0            1.0            0.0   \n",
       "\n",
       "   rank-query-mean  num_in_top-1  num_in_top-3  \n",
       "0         1.531250            42            56  \n",
       "1         1.265625            41            56  \n",
       "2         8.406250            36            46  \n",
       "3         1.531250            42            56  \n",
       "4         1.531250            42            56  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate mean rank of ground truth for each method\n",
    "df_results['rank-query-mean'] = df_results[[f'rank-query-{i}' for i in range(64)]].mean(axis=1)\n",
    "\n",
    "# Calculate number of ground truth results which appear in top 3\n",
    "for i in [1,3]:\n",
    "    df_results[f'num_in_top-{i}'] = (df_results[[f'rank-query-{j}' for j in range(64)]] < i).sum(axis=1)\n",
    "\n",
    "\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method_name</th>\n",
       "      <th>rank-query-mean</th>\n",
       "      <th>num_in_top-1</th>\n",
       "      <th>num_in_top-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>multi-qa-mpnet-base-dot-v1_transcript_dot-score</td>\n",
       "      <td>1.140625</td>\n",
       "      <td>37</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>all-MiniLM-L6-v2_title-transcript_manhattan</td>\n",
       "      <td>1.187500</td>\n",
       "      <td>37</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>all-MiniLM-L6-v2_title-transcript_euclidean</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>37</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all-MiniLM-L6-v2_title_manhattan</td>\n",
       "      <td>1.265625</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>all-MiniLM-L6-v2_transcript_dot-score</td>\n",
       "      <td>1.343750</td>\n",
       "      <td>37</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        method_name  rank-query-mean  \\\n",
       "44  multi-qa-mpnet-base-dot-v1_transcript_dot-score         1.140625   \n",
       "31      all-MiniLM-L6-v2_title-transcript_manhattan         1.187500   \n",
       "30      all-MiniLM-L6-v2_title-transcript_euclidean         1.250000   \n",
       "1                  all-MiniLM-L6-v2_title_manhattan         1.265625   \n",
       "34            all-MiniLM-L6-v2_transcript_dot-score         1.343750   \n",
       "\n",
       "    num_in_top-1  num_in_top-3  \n",
       "44            37            57  \n",
       "31            37            55  \n",
       "30            37            56  \n",
       "1             41            56  \n",
       "34            37            55  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = df_results[['method_name', 'rank-query-mean','num_in_top-1', 'num_in_top-3']]\n",
    "df_summary.sort_values(by='rank-query-mean').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method_name</th>\n",
       "      <th>rank-query-mean</th>\n",
       "      <th>num_in_top-1</th>\n",
       "      <th>num_in_top-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all-MiniLM-L6-v2_title_euclidean</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>multi-qa-distilbert-cos-v1_title_euclidean</td>\n",
       "      <td>2.296875</td>\n",
       "      <td>42</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all-MiniLM-L6-v2_title_cos-sim</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all-MiniLM-L6-v2_title_dot-score</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>multi-qa-mpnet-base-dot-v1_title-transcript_ma...</td>\n",
       "      <td>2.296875</td>\n",
       "      <td>42</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          method_name  rank-query-mean  \\\n",
       "0                    all-MiniLM-L6-v2_title_euclidean         1.531250   \n",
       "10         multi-qa-distilbert-cos-v1_title_euclidean         2.296875   \n",
       "3                      all-MiniLM-L6-v2_title_cos-sim         1.531250   \n",
       "4                    all-MiniLM-L6-v2_title_dot-score         1.531250   \n",
       "41  multi-qa-mpnet-base-dot-v1_title-transcript_ma...         2.296875   \n",
       "\n",
       "    num_in_top-1  num_in_top-3  \n",
       "0             42            56  \n",
       "10            42            58  \n",
       "3             42            56  \n",
       "4             42            56  \n",
       "41            42            54  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.sort_values(by='num_in_top-1', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method_name</th>\n",
       "      <th>rank-query-mean</th>\n",
       "      <th>num_in_top-1</th>\n",
       "      <th>num_in_top-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>multi-qa-distilbert-cos-v1_title-transcript_ma...</td>\n",
       "      <td>2.312500</td>\n",
       "      <td>41</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>multi-qa-distilbert-cos-v1_title-transcript_eu...</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>41</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>multi-qa-distilbert-cos-v1_title_dot-score</td>\n",
       "      <td>2.296875</td>\n",
       "      <td>42</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>multi-qa-distilbert-cos-v1_title_cos-sim</td>\n",
       "      <td>2.296875</td>\n",
       "      <td>42</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>multi-qa-distilbert-cos-v1_title_euclidean</td>\n",
       "      <td>2.296875</td>\n",
       "      <td>42</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          method_name  rank-query-mean  \\\n",
       "36  multi-qa-distilbert-cos-v1_title-transcript_ma...         2.312500   \n",
       "35  multi-qa-distilbert-cos-v1_title-transcript_eu...         2.109375   \n",
       "14         multi-qa-distilbert-cos-v1_title_dot-score         2.296875   \n",
       "13           multi-qa-distilbert-cos-v1_title_cos-sim         2.296875   \n",
       "10         multi-qa-distilbert-cos-v1_title_euclidean         2.296875   \n",
       "\n",
       "    num_in_top-1  num_in_top-3  \n",
       "36            41            59  \n",
       "35            41            59  \n",
       "14            42            58  \n",
       "13            42            58  \n",
       "10            42            58  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.sort_values(by='num_in_top-3', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_choice = \"all-MiniLM-L6-v2_title_cos-sim\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
